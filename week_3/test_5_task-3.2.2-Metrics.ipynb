{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Измерение качества моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это практическое задание посвящено ознакомлению с инструментами оценки качества моделей машинного обучения, которые предоставляет библиотека `scikit-learn`. Метрики качества, представленные различными функциями, находятся в модуле `sklearn.metrics`. Мы начнем с загрузки набора данных из файла `data.csv` при помощи функции `read_csv` из библиотеки `pandas`. Этот набор данных содержит информацию о предсказаниях различных алгоритмов машинного обучения для решения задачи классификации. Колонка `prediction` - это результаты работы одного из этих алгоритмов. Целевая переменная содержится в столбце `target` (класс 0 или 1). Подсчитайте значение `true negative`, `false negative`, `true positive` и `false positive`. Запишите эти значения через запятую, сохраняя приведенный порядок, в переменную `answer1`, которая будет являтся строкой. Далее, посчитайте для этих данных значение таких метрик как `precision`, `recall` и `f1 score` с точностью до двух знаков после запятой. Запишите результаты в строго заданном порядке через запятую в переменную `answer2`, которая так же будет являться строкой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>scores_1</th>\n",
       "      <th>scores_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction  scores_1  scores_2  target\n",
       "0             1      0.89       0.9       1\n",
       "1             0      0.06       0.0       0\n",
       "2             1      0.71       0.6       0\n",
       "3             1      1.00       0.7       1\n",
       "4             1      1.00       1.0       1\n",
       "..          ...       ...       ...     ...\n",
       "183           1      0.98       1.0       1\n",
       "184           1      1.00       1.0       1\n",
       "185           1      0.99       1.0       1\n",
       "186           1      1.00       1.0       1\n",
       "187           1      0.96       1.0       1\n",
       "\n",
       "[188 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# table\n",
    "t = pd.read_csv( \"task-3.2.2/data.csv\" )\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 63,   7],\n",
       "       [  4, 114]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion_matrix(y_true, y_pred)\n",
    "# Returns\n",
    "#    -------\n",
    "#    C : ndarray of shape (n_classes, n_classes)\n",
    "#        Confusion matrix whose i-th row and j-th      i- строка, j-столбец\n",
    "#        column entry indicates the number of\n",
    "#        samples with true label being i-th class\n",
    "#        and predicted label being j-th class.\n",
    "#      Предсказание\n",
    "# И     | 0    1\n",
    "# с   __|________\n",
    "# т   0 | TN  FP\n",
    "# и   1 | FN  TP\n",
    "# н\n",
    "# а\n",
    "# Returns C\n",
    "#    the count of true negatives is :math:`C_{0,0}`, \n",
    "#                false negatives is :math:`C_{1,0}`, \n",
    "#                 true positives is :math:`C_{1,1}` \n",
    "#                false positives is :math:`C_{0,1}`\n",
    "\n",
    "cm = confusion_matrix(t[\"target\"], t[\"prediction\"])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'63,4,114,7'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = cm[0,0]\n",
    "fn = cm[1,0]\n",
    "tp = cm[1,1]\n",
    "fp = cm[0,1]\n",
    "\n",
    "## or\n",
    "#tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "answer1 = f\"{tn},{fn},{tp},{fp}\"\n",
    "answer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my precision_score: 0.9421\n",
      "precision_score:    0.9421\n",
      "my recall:          0.9661\n",
      "recall:             0.9661\n",
      "my f1:              0.9540\n",
      "f1:                 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.94,0.97,0.95'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# precision_score\n",
    "pr_my = tp / (tp + fp)\n",
    "pr = precision_score(t[\"target\"], t[\"prediction\"])\n",
    "\n",
    "# recall\n",
    "re_my = tp / (tp + fn)\n",
    "re = recall_score(t[\"target\"], t[\"prediction\"])\n",
    "\n",
    "# f1\n",
    "f1_my = 2 * (pr * re) / (pr + re)\n",
    "f1 = f1_score(t[\"target\"], t[\"prediction\"])\n",
    "\n",
    "print(\"my precision_score: {:.4f}\".format(pr_my))\n",
    "print(\"precision_score:    {:.4f}\".format(pr))\n",
    "print(\"my recall:          {:.4f}\".format(re_my))\n",
    "print(\"recall:             {:.4f}\".format(re))\n",
    "print(\"my f1:              {:.4f}\".format(f1_my))\n",
    "print(\"f1:                 {:.4f}\".format(f1))\n",
    "\n",
    "answer2 = f\"{pr:.2f},{re:.2f},{f1:.2f}\"\n",
    "answer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В столбцах `scores_1` и `scores_2` содержаться оценки вероятности пренадлежности объектов к классу 1 для двух разных алгоритмов машинного обучения. Рассчитайте площадь под ROC-кривой для каждого алгоритма и сравните их. В качестве ответа `answer3` приведите большее из двух значений, округленное до трех знаков после запятой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>scores_1</th>\n",
       "      <th>scores_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction  scores_1  scores_2  target\n",
       "0           1      0.89       0.9       1\n",
       "1           0      0.06       0.0       0\n",
       "2           1      0.71       0.6       0\n",
       "3           1      1.00       0.7       1\n",
       "4           1      1.00       1.0       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_1: 0.9934624697336562\n",
      "roc_auc_2: 0.9854116222760291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9934624697336562"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_1 = roc_auc_score(t[\"target\"], t[\"scores_1\"])\n",
    "roc_auc_2 = roc_auc_score(t[\"target\"], t[\"scores_2\"])\n",
    "\n",
    "print(\"roc_auc_1:\", roc_auc_1)\n",
    "print(\"roc_auc_2:\", roc_auc_2)\n",
    "\n",
    "answer3 = max(roc_auc_1,roc_auc_2)\n",
    "answer3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод скользящего контроля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во второй части данного практического задания мы изучать различные методы оценки моделей машинного обучения. Загрузите набор данных `Breast Cancer Wisconsin (Diagnostic)`, используя функцию `load_breast_cancer` из модуля `sklearn.datasets`. Этот датасет позволяет решать задачу предсказания рака груди по различным характеристикам опухоли. В данном случае, целевая переменная принимает два значения, соответствующие доброкачественной и злокачественной опухоли. Проверьте, является ли данная выборка сбалансированной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this a balanced dataset? False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "counts = pd.value_counts(y)\n",
    "print(\"Is this a balanced dataset? {}\".format(counts[1] == counts[0]))\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "target_names: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "\n",
    "print(\"feature_names:\", data.feature_names)\n",
    "print(\"target_names:\", data.target_names)\n",
    "# features = data.data\n",
    "# target = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый метод, который мы будем использовать, - это случайное разбиение датасета на тренировочную и тестовую выборку с помощью функции `train_test_split` из `sklearn.model_selection` с параметрами `random_state=3` и `test_size=0.33`. Если выборка является несбалансированной передайте целевую переменную в эту функцию в качестве аргумента `stratify`.\n",
    "\n",
    "Обучите логистическую регрессию (класс `LogisticRegression` из модуля `sklearn.linear_model`) с параметром конструктора `random_state=42` и метод K ближайших соседей (класс `KNeighborsClassifier` из модуля `sklearn.neighbors`) на тренировочной выборке. Оцените качество на тестовой выборке для каждой из моделей. В качестве метрики качества используйте `recall`. Какая из моделей показывает лучший результат? Ответом на это задание `answer4` является этот результат, округленный до трех знаков после запятой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов, изначально :\n",
      " 1    357\n",
      "0    212\n",
      "dtype: int64\n",
      "Отношение '1' / '0': 0.5938375350140056\n",
      "-------------------------------------------\n",
      "Баланс классов, тренировочная выборка :\n",
      " 1    239\n",
      "0    142\n",
      "dtype: int64\n",
      "Отношение '1' / '0': 0.5941422594142259\n",
      "-------------------------------------------\n",
      "Баланс классов, тестовая выборка :\n",
      " 1    118\n",
      "0     70\n",
      "dtype: int64\n",
      "Отношение '1' / '0': 0.5932203389830508\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# датасет достаточно сбалансирован, на мой взгляд.\n",
    "# Тем не менее, для надежности указываю  stratify=y, чтобы сохранять пропорции классов\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=3, stratify=y)\n",
    "\n",
    "for d , name in zip([y, y_train, y_test],['изначально','тренировочная выборка','тестовая выборка']):\n",
    "    counts = pd.value_counts(d)\n",
    "    ration = counts[0]/counts[1]\n",
    "    print(\"Баланс классов,\", name, \":\\n\", counts)\n",
    "    print(\"Отношение '1' / '0':\", ration)\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "??? 0.9745762711864406 0.9745762711864406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9745762711864406"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regres = LogisticRegression(random_state=42, max_iter = 10000)\n",
    "kneighbors_clas = KNeighborsClassifier()\n",
    "\n",
    "# train\n",
    "logistic_regres.fit(X_train, y_train)\n",
    "kneighbors_clas.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "log_regres_pred = logistic_regres.predict(X_test)\n",
    "kneighbers_pred = kneighbors_clas.predict(X_test)\n",
    "#print(log_regres_pred == kneighbers_pred)\n",
    "\n",
    "\n",
    "recall_log_regres = recall_score(y_test, log_regres_pred)\n",
    "recall_kneighbors = recall_score(y_test, kneighbers_pred)\n",
    "\n",
    "print(\"\\n???\",recall_log_regres, recall_kneighbors)\n",
    "\n",
    "answer4 = max(recall_log_regres,recall_kneighbors)\n",
    "answer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы проведем оценку каждой из этих моделей в соответствии с методом скользящего контроля с помощью функции `cross_val_score` из модуля `sklearn.model_selection`. В качестве параметра кросс-валидации `cv` в этой функции используйте экземпляр класса `StratifiedKFold` из `sklearn.model_selection` с тремя разбиениями. \n",
    "\n",
    "Функция `cross_val_score` возвращает количество оценок, соответствующие числу разбиений.\n",
    "В качестве итогового результата используете среднее значение полученных оценок с помощью метрики `recall`. Какая модель работает лучше в это случае? Какие выводы можно из этого сделать? Ответом на это задание `answer5` является лучший итоговый результат, округленный до трех знаков после запятой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0, score_1: 0.9421052631578948, score_2: 0.9\n",
      "Split 1, score_1: 0.9631578947368421, score_2: 0.9473684210526315\n",
      "Split 2, score_1: 0.9417989417989417, score_2: 0.9206349206349206\n",
      "\n",
      "Logistic regression\n",
      "Cross value score (recall) [0.98319328 0.99159664 0.93277311]\n",
      "Mean cross val score 0.9691876750700281\n",
      "\n",
      "KNeighbors classification\n",
      "Cross value score (recall) [0.96638655 0.96638655 0.94117647]\n",
      "Mean cross val score 0.957983193277311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# разбивщик на n кросс-датасетов\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "    x_train, x_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # обучаем\n",
    "    logistic_regres.fit(x_train, y_train)\n",
    "    kneighbors_clas.fit(x_train, y_train)\n",
    "    \n",
    "    # проверяем\n",
    "    score_1 = logistic_regres.score(x_test, y_test)\n",
    "    score_2 = kneighbors_clas.score(x_test, y_test)\n",
    "    \n",
    "    print(\"Split {}, score_1: {}, score_2: {}\".format(split_idx, score_1, score_2))\n",
    "    \n",
    "cv_score_1 = cross_val_score(\n",
    "    logistic_regres, X, y,\n",
    "    scoring=\"recall\", cv=cv)\n",
    "cv_score_2 = cross_val_score(\n",
    "    kneighbors_clas, X, y,\n",
    "    scoring=\"recall\", cv=cv)\n",
    "\n",
    "print(\"\\nLogistic regression\")\n",
    "print(\"Cross value score (recall)\", cv_score_1)\n",
    "print(\"Mean cross val score\", cv_score_1.mean())\n",
    "\n",
    "print(\"\\nKNeighbors classification\")\n",
    "print(\"Cross value score (recall)\", cv_score_2)\n",
    "print(\"Mean cross val score\", cv_score_2.mean())\n",
    "\n",
    "answer5 = max(cv_score_1.mean(),cv_score_2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строка с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN,FN,TP,FP = 63,4,114,7\n",
      "Precision,Recall,F1 Score = 0.94,0.97,0.95\n",
      "Best ROC AUC Score 0.993\n",
      "Random Split 0.975\n",
      "Cross Val Score 0.969\n"
     ]
    }
   ],
   "source": [
    "output = \"\"\"TN,FN,TP,FP = {0}\n",
    "Precision,Recall,F1 Score = {1}\n",
    "Best ROC AUC Score {2:.3f}\n",
    "Random Split {3:.3f}\n",
    "Cross Val Score {4:.3f}\"\"\"\n",
    "print(output.format(answer1, answer2, answer3, answer4, answer5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
